{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d525ee1",
   "metadata": {},
   "source": [
    "# 이미지분석_사진유사도비교_서비스_mediapipe_deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd0a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 유사도 분석 모델 다운로드\n",
    "!wget -O embedder.tflite -q https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25b1ce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = ['burger.jpg', 'burger_crop.jpg']\n",
    "\n",
    "for name in image_filenames:\n",
    "    url = f\"https://storage.googleapis.com/mediapipe-assets/{name}\"\n",
    "    urllib.request.urlretrieve(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74936bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_height = 480\n",
    "desired_width = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_show(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (desired_width, math.floor(h/(w/desired_width))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w/(h/desired_height)), desired_height))\n",
    "    return img\n",
    "        \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50079f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 미리보기\n",
    "images = {name: cv2.imread(name) for name in image_filenames}\n",
    "for name, image in images.items():\n",
    "    print(name)\n",
    "    resized_image = resize_and_show(image)\n",
    "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33976bc7",
   "metadata": {},
   "source": [
    "# 미디어 파이프 모델을 불러와서 유사도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path=\"./embedder.tflite\")\n",
    "l2_normalize = True\n",
    "quantize = True\n",
    "options = vision.ImageEmbedderOptions(\n",
    "        base_options=base_options, l2_normalize=l2_normalize, quantize=quantize\n",
    "        )\n",
    "\n",
    "# create image embedder\n",
    "with vision.ImageEmbedder.create_from_options(options) as embedder:\n",
    "    first_image = mp.Image.create_from_file(image_filenames[0])\n",
    "    second_image = mp.Image.create_from_file(image_filenames[1])\n",
    "    first_embedding_result = embedder.embed(first_image)\n",
    "    second_embedding_result = embedder.embed(second_image)\n",
    "    \n",
    "    #유사도 비교(코사인 유사도 사용)\n",
    "    similarity = vision.ImageEmbedder.cosine_similarity(\n",
    "            first_embedding_result.embeddings[0],\n",
    "            second_embedding_result.embeddings[0])\n",
    "    print(similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389aae5",
   "metadata": {},
   "source": [
    "# 미디어 파이프 모델로 얼굴 유사도 판별하기\n",
    "* 사진 2장 필요\n",
    "* 사진에서 얼굴 찾기 - 얼굴 찾는 모델\n",
    "* 얼굴만 크롭\n",
    "* 얼굴을 숫자로 임베딩 - 이미지를 숫자로 벡터화(임베딩)하는 모델\n",
    "* 임베딩 된 얼굴을 비교\n",
    "* 유사도 출력\n",
    "* 간단한 서비스 구현을 위해 gradio라이브러리 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155ea61",
   "metadata": {},
   "source": [
    "# 사진에서 얼굴 추출하는 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(image_np):\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as detector:\n",
    "        results = detector.process(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
    "        if not results.detections:\n",
    "            return None\n",
    "        bbox = results.detections[0].location_data.relative_bounding_box\n",
    "        h, w, _ = image_np.shape\n",
    "        x_min = int(bbox.xmin * w)\n",
    "        y_min = int(bbox.ymin * h)\n",
    "        width = int(bbox.width * w)\n",
    "        height = int(bbox.height * h)\n",
    "        return image_np[y_min:y_min+height, x_min:x_min+width]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0418b9a",
   "metadata": {},
   "source": [
    "# 얼굴 유사도 비교 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ddac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(image1, image2):\n",
    "    # 이미지 없는 경우 예외처리\n",
    "    if image1 is None or image2 is None:\n",
    "        return \"이미지를 두 장 모두 업로드하세요.\"\n",
    "    \n",
    "    img1 = cv2.cvtColor(np.array(image1), cv2.COLOR_BGR2RGB)\n",
    "    img2 = cv2.cvtColor(np.array(image2), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # crop_face함수로 얼굴만 추출해서 저장\n",
    "    face1 = crop_face(img1)\n",
    "    face2 = crop_face(img2)\n",
    "    \n",
    "    if face1 is None or face2 is None:\n",
    "        return \"얼굴 감지 실패\"\n",
    "    \n",
    "    cv2.imwrite(\"face1.jpg\", face1)\n",
    "    cv2.imwrite(\"face2.jpg\", face2)\n",
    "    \n",
    "    base_options = python.BaseOptions(model_asset_path=\"./embedder.tflite\")\n",
    "    options = vision.ImageEmbedderOptions(\n",
    "            base_options=base_options, l2_normalize=True, quantize=True\n",
    "            )\n",
    "\n",
    "    # create image embedder\n",
    "    with vision.ImageEmbedder.create_from_options(options) as embedder:\n",
    "        face1_mp = mp.Image.create_from_file(\"face1.jpg\")\n",
    "        face2_mp = mp.Image.create_from_file(\"face2.jpg\")\n",
    "        emb1 = embedder.embed(face1_mp).embeddings[0]\n",
    "        emb2 = embedder.embed(face2_mp).embeddings[0]\n",
    "\n",
    "        #유사도 비교(코사인 유사도 사용)\n",
    "        similarity = vision.ImageEmbedder.cosine_similarity(\n",
    "                emb1,\n",
    "                emb2)\n",
    "        return f\"얼굴 유사도: {similarity:.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b33ae8",
   "metadata": {},
   "source": [
    "# gradio를 이용해서 UI 및 간이 서버 만들기\n",
    "* 내부적으로 fastapi 프레임워크 사용: 웹서버"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0805ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"얼굴 유사도 비교\")\n",
    "    \n",
    "    with gr.Tab('Image Upload'):\n",
    "        with gr.Column():\n",
    "            image1 = gr.Image(label=\"First Image\")\n",
    "        with gr.Column():\n",
    "            image2 = gr.Image(label=\"Second Image\")\n",
    "    output = gr.Textbox(label=\"얼굴 유사도: \")\n",
    "    convert_btn = gr.Button(\"유사도 비교하기\")\n",
    "    convert_btn.click(\n",
    "        fn=image_to_text, inputs=[image1, image2], outputs=output)\n",
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab635d8a",
   "metadata": {},
   "source": [
    "# Deepface를 이용해 정확도 높은 얼굴인식 프로그램 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deepface\n",
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ca6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118462fe",
   "metadata": {},
   "source": [
    "# 유사도 %로 표시하는 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_distance_to_similarity(distance,threshold, verified):\n",
    "    if verified:\n",
    "        #일치할 경우\n",
    "        ratio = max(0, 1 -(distance/threshold))\n",
    "        return round(90 + ratio * 10, 2)\n",
    "    else:\n",
    "        # 불일치 할 경우\n",
    "        ratio = max(0, 1 - (distance/ (threshold * 2)))\n",
    "        return round(ratio * 60, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51f1ad",
   "metadata": {},
   "source": [
    "# 얼굴 유사도 비교 함수 (ArcFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        return \"두 이미지 모두 업로드 해주세요.\"\n",
    "    image1 = cv2.cvtColor(np.array(image1), cv2.COLOR_RGB2BGR)\n",
    "    image2 = cv2.cvtColor(np.array(image2), cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"image1.jpg\", image1)\n",
    "    cv2.imwrite(\"image2.jpg\", image2)\n",
    "    \n",
    "    try:\n",
    "        threshold = 0.68 # ArcFace 기준 두 이미지가 일치하는 기준\n",
    "        result = DeepFace.verify(\"image1.jpg\", \"image2.jpg\", model_name=\"ArcFace\", enforce_detection=True)\n",
    "        distance = result['distance']\n",
    "        verified = result['verified']\n",
    "        similarity_score = convert_distance_to_similarity(distance, threshold, verified)\n",
    "        result_text = f\"ArcFace 기준 얼굴 유사도 분석:\\n유사도: {similarity_score:.2f}%\\n얼굴 일치 여부: {'일치' if verified else '불일치'}\"\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        return f\"오류: {str(e)}\" \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364a186",
   "metadata": {},
   "source": [
    "# Gradio로 입출력 인터페이스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c331318",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"얼굴 유사도 비교 (ArcFace 기반)\")\n",
    "    with gr.Tab(\"이미지 업로드\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image1 = gr.Image(label=\"첫 번째 얼굴\")\n",
    "            with gr.Column():\n",
    "                image2 = gr.Image(label=\"두 번째 얼굴\")\n",
    "        output = gr.Textbox(label=\"분석 결과\")\n",
    "        compare_btn = gr.Button(\"유사도 비교\")\n",
    "        compare_btn.click(fn=image_to_text, inputs=[image1, image2], outputs=output)\n",
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668c4f7",
   "metadata": {},
   "source": [
    "# 여러 모델과 유사도 측정 측도 변경하면서 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f5f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c68158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 기준으로 정렬된 모델 목록\n",
    "models = [\n",
    "    'ArcFace',      # 99.83%\n",
    "    'SFace',        # ~99.5%\n",
    "    'Facenet512',   # 99.20%\n",
    "    'Facenet',      # 99%\n",
    "    'GhostFaceNet', # ~98.8%\n",
    "    'VGG-Face',     # 98.78%\n",
    "    'OpenFace',     # 93.60%\n",
    "    'DeepID'        # 89%\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07011186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 거리 측도\n",
    "recommended_metric = {\n",
    "    'ArcFace' : \"cosine\",      # 99.83%\n",
    "    'SFace' : \"cosine\",        # ~99.5%\n",
    "    'Facenet512' : \"euclidean_l2\",   # 99.20%\n",
    "    'Facenet' : \"euclidean_l2\",      # 99%\n",
    "    'GhostFaceNet' : \"cosine\", # ~98.8%\n",
    "    'VGG-Face' : \"euclidean\",     # 98.78%\n",
    "    'OpenFace' : \"euclidean_l2\",     # 93.60%\n",
    "    'DeepID' : \"euclidean\"        # 89%\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 threshold\n",
    "model_thresholds = {\n",
    "    'ArcFace' : 0.68,      # 99.83%\n",
    "    'SFace' : 0.593,        # ~99.5%\n",
    "    'Facenet512' : 0.3,   # 99.20%\n",
    "    'Facenet' : 0.4,      # 99%\n",
    "    'GhostFaceNet' : 0.25, # ~98.8%\n",
    "    'VGG-Face' : 0.4,     # 98.78%\n",
    "    'OpenFace' : 0.55,     # 93.60%\n",
    "    'DeepID' : 0.17       # 89%\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8079a49",
   "metadata": {},
   "source": [
    "# 유사도 %로 표시하는 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ddda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_distance_to_similarity(distance,threshold, verified):\n",
    "    if verified:\n",
    "        #일치할 경우\n",
    "        ratio = max(0, 1 -(distance/threshold))\n",
    "        return round(90 + ratio * 10, 2)\n",
    "    else:\n",
    "        # 불일치 할 경우\n",
    "        ratio = max(0, 1 - (distance/ (threshold * 2)))\n",
    "        return round(ratio * 60, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d27a13",
   "metadata": {},
   "source": [
    "# 얼굴 크롭 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(image_np):\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as detector:\n",
    "        results = detector.process(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
    "        if not results.detections:\n",
    "            return None\n",
    "        bbox = results.detections[0].location_data.relative_bounding_box\n",
    "        h, w, _ = image_np.shape\n",
    "        x_min = int(bbox.xmin * w)\n",
    "        y_min = int(bbox.ymin * h)\n",
    "        width = int(bbox.width * w)\n",
    "        height = int(bbox.height * h)\n",
    "        return image_np[y_min:y_min+height, x_min:x_min+width]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f96d2f",
   "metadata": {},
   "source": [
    "# 얼굴 유사도 비교 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0085ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(image1, image2, model):\n",
    "    if image1 is None or image2 is None:\n",
    "        return \"두 이미지 모두 업로드 해주세요.\"\n",
    "    \n",
    "    img1 = cv2.cvtColor(np.array(image1), cv2.COLOR_BGR2RGB)\n",
    "    img2 = cv2.cvtColor(np.array(image2), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # crop_face함수로 얼굴만 추출해서 저장\n",
    "    face1 = crop_face(img1)\n",
    "    face2 = crop_face(img2)\n",
    "    \n",
    "    if face1 is None or face2 is None:\n",
    "        return \"얼굴 감지 실패\"\n",
    "    \n",
    "    cv2.imwrite(\"face1.jpg\", face1)\n",
    "    cv2.imwrite(\"face2.jpg\", face2)\n",
    "    \n",
    "    \n",
    "    #추천 metric 및 threshold 불러오기\n",
    "    metric = recommended_metric.get(model, \"cosine\")\n",
    "    threshold = model_thresholds.get(model, 0.5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        result = DeepFace.verify(\"face1.jpg\", \"face2.jpg\", model_name=model,\n",
    "                                 distance_metric=metric,\n",
    "                                 enforce_detection=True)\n",
    "        distance = result['distance']\n",
    "        verified = result['verified']\n",
    "        similarity_score = convert_distance_to_similarity(distance, threshold, verified)\n",
    "        result_text = f\"{model} 기준 얼굴 유사도 분석:\\n유사도: {similarity_score:.2f}%\\n얼굴 일치 여부: {'일치' if verified else '불일치'}\"\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        return f\"오류: {str(e)}\" \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c18ee",
   "metadata": {},
   "source": [
    "# Gradio로 입출력 인터페이스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d024b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"얼굴 유사도 비교 (ArcFace 기반)\")\n",
    "    with gr.Tab(\"이미지 업로드\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image1 = gr.Image(label=\"첫 번째 얼굴\")\n",
    "            with gr.Column():\n",
    "                image2 = gr.Image(label=\"두 번째 얼굴\")\n",
    "                \n",
    "        model = gr.Dropdown(label='model', choices=models, value='ArcFace')\n",
    "        output = gr.Textbox(label=\"분석 결과\")\n",
    "        compare_btn = gr.Button(\"유사도 비교\")\n",
    "        compare_btn.click(fn=image_to_text, inputs=[image1, image2, model], outputs=output)\n",
    "app.launch(inline=False, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c87e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6110b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a904e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc520a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc37bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
